{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03.Sample LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdgzCzDQm2Si"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first, dropout, bidirectional)\n",
        "```\n",
        "1.input_size: embedding_dim  \n",
        "2.hidden_size: number of LSTM per layer  \n",
        "3.num_layers: number of layers in RNN  \n",
        "4.batch_first: default False ([seq_len, batch, feature]); True ([batch, seq_len, feature])  \n",
        "5.dropout: default 0. Deactivate some parameters to speed up training/prevent overfitting.  \n",
        "6/bidirectional: default False.  \n",
        "Initialize:  \n",
        "Input data and h_0 and c_0. E.g.  \n",
        "```\n",
        "lstm(input, (h_n, c_n))\n",
        "```"
      ],
      "metadata": {
        "id": "ua-3D_VWqCyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.output: (seq_len, batch, num_directions*hidden_size) -> batch_first=False  \n",
        "2.h_n: (num_layers * num_directions, batch, hidden_size)  \n",
        "3.c_n: (num_layers * num_directions, batch, hidden_size) "
      ],
      "metadata": {
        "id": "RjAnqaMk1et1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "LLevRcxs4146"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "seq_len = 20\n",
        "vocab_size = 100\n",
        "embedding_dim = 30\n",
        "hidden_size = 18\n",
        "num_layer = 1"
      ],
      "metadata": {
        "id": "_a_oQfbq41eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fake Data**"
      ],
      "metadata": {
        "id": "LegPOsSo6S0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randint(low=0, high=100, size=[batch_size, seq_len])\n",
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VTfFrtI4qAT",
        "outputId": "0e265b19-03fd-4169-cc57-888d773048de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[37, 26, 97, 69, 92, 21, 90, 93, 39, 79, 71, 43, 65, 57, 92, 11,  0, 10,\n",
              "         51,  1],\n",
              "        [56, 71, 56, 83,  6, 56,  1, 26, 64, 95, 20, 66, 10, 16, 71, 19, 20, 75,\n",
              "         25, 63],\n",
              "        [93, 85, 26, 28, 64, 34, 69, 52, 92, 30, 48, 24, 60, 43, 77, 47, 47, 47,\n",
              "         65, 31],\n",
              "        [13, 63, 81, 21, 58, 52, 71, 30, 40, 70, 82, 66, 11, 47,  7, 35, 40, 71,\n",
              "         78, 78],\n",
              "        [53, 68, 83, 14, 88, 93, 71, 13, 72, 14, 77,  1, 11, 29, 75,  3, 87, 67,\n",
              "         55, 33],\n",
              "        [90, 21,  0,  1, 65, 31, 28, 38, 27, 89, 82, 70, 65, 38, 58, 59, 31, 73,\n",
              "         75, 48],\n",
              "        [83, 93, 12, 74,  0, 49, 90, 24, 89, 67, 20,  8, 17, 95, 75, 72, 60, 94,\n",
              "         95, 50],\n",
              "        [88, 29, 99, 88, 22, 64, 84, 20,  2, 76,  8, 45, 38, 54, 72, 51, 90, 56,\n",
              "         61, 42],\n",
              "        [25, 13, 19, 86, 48, 31, 33, 48, 32,  7, 86,  8, 38, 95, 50, 73, 87, 86,\n",
              "         33, 81],\n",
              "        [28, 93, 48, 29, 91, 65, 56, 62, 68, 54, 71,  0,  2, 60, 75, 32, 74, 37,\n",
              "          8,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding**"
      ],
      "metadata": {
        "id": "pucJR8Hw6Vfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)"
      ],
      "metadata": {
        "id": "hOsy1cad5dp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeded = embedding(input)  # (batch_size, seq_len, embedding_dim) (10, 20, 30)"
      ],
      "metadata": {
        "id": "-iRWfCUG6HXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "aTptCSIU6YLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layer, batch_first=True)"
      ],
      "metadata": {
        "id": "LeIvBb516Phw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output, (h_n, c_n) = lstm(input_embeded)"
      ],
      "metadata": {
        "id": "IaSnl1v96taE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.size())  # (batch_size, seq_len, num_directions * hidden_size) (10, 20, 18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKivC1kw6_EB",
        "outputId": "bb08d3ec-a28e-4e17-971a-f755ac78e9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 20, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(h_n.size()) # (num_directions * num_layers, batch_size, hidden_size) (1, 20, 18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_mw2vrf7DSY",
        "outputId": "61d2bc5a-f24a-49f5-f95e-e4d8e6013fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(c_n.size()) # (num_directions * num_layers, batch_size, hidden_size) (1, 20, 18)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCB33nwA7EyA",
        "outputId": "0c77e5d0-d246-483a-a4c3-c5de20fe8bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 18])\n"
          ]
        }
      ]
    }
  ]
}