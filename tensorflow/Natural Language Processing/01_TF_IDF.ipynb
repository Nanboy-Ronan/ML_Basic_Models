{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01.TF-IDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r6fnBtEJhsmS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fake Data**"
      ],
      "metadata": {
        "id": "bAs0kN7-jkqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"it is a good day, I like to stay here\",\n",
        "    \"I am happy to be here\",\n",
        "    \"I am bob\",\n",
        "    \"it is sunny today\",\n",
        "    \"I have a party today\",\n",
        "    \"it is a dog and that is a cat\",\n",
        "    \"there are dog and cat on the tree\",\n",
        "    \"I study hard this morning\",\n",
        "    \"today is a good day\",\n",
        "    \"tomorrow will be a good day\",\n",
        "    \"I like coffee, I like book and I like apple\",\n",
        "    \"I do not like it\",\n",
        "    \"I am kitty, I like bob\",\n",
        "    \"I do not care who like bob, but I like kitty\",\n",
        "    \"It is coffee time, bring your cup\",\n",
        "]"
      ],
      "metadata": {
        "id": "vQaKqCDxjmCo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess Data**"
      ],
      "metadata": {
        "id": "QFrox_kPj7WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_words = [d.replace(\",\", \"\").split(\" \") for d in docs]\n",
        "docs_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD-A0ZQhj4_w",
        "outputId": "3e6ba958-cb8e-452b-f2b6-afa46a288846"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['it', 'is', 'a', 'good', 'day', 'I', 'like', 'to', 'stay', 'here'],\n",
              " ['I', 'am', 'happy', 'to', 'be', 'here'],\n",
              " ['I', 'am', 'bob'],\n",
              " ['it', 'is', 'sunny', 'today'],\n",
              " ['I', 'have', 'a', 'party', 'today'],\n",
              " ['it', 'is', 'a', 'dog', 'and', 'that', 'is', 'a', 'cat'],\n",
              " ['there', 'are', 'dog', 'and', 'cat', 'on', 'the', 'tree'],\n",
              " ['I', 'study', 'hard', 'this', 'morning'],\n",
              " ['today', 'is', 'a', 'good', 'day'],\n",
              " ['tomorrow', 'will', 'be', 'a', 'good', 'day'],\n",
              " ['I', 'like', 'coffee', 'I', 'like', 'book', 'and', 'I', 'like', 'apple'],\n",
              " ['I', 'do', 'not', 'like', 'it'],\n",
              " ['I', 'am', 'kitty', 'I', 'like', 'bob'],\n",
              " ['I', 'do', 'not', 'care', 'who', 'like', 'bob', 'but', 'I', 'like', 'kitty'],\n",
              " ['It', 'is', 'coffee', 'time', 'bring', 'your', 'cup']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = itertools.chain(*docs_words)\n",
        "print('chain: ', temp)\n",
        "temp = list(temp)\n",
        "print('list: ', temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEsRjQ1jl_YG",
        "outputId": "4a7cda75-af07-4792-ae50-555918f78b08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chain:  <itertools.chain object at 0x7fae3511a110>\n",
            "list:  ['it', 'is', 'a', 'good', 'day', 'I', 'like', 'to', 'stay', 'here', 'I', 'am', 'happy', 'to', 'be', 'here', 'I', 'am', 'bob', 'it', 'is', 'sunny', 'today', 'I', 'have', 'a', 'party', 'today', 'it', 'is', 'a', 'dog', 'and', 'that', 'is', 'a', 'cat', 'there', 'are', 'dog', 'and', 'cat', 'on', 'the', 'tree', 'I', 'study', 'hard', 'this', 'morning', 'today', 'is', 'a', 'good', 'day', 'tomorrow', 'will', 'be', 'a', 'good', 'day', 'I', 'like', 'coffee', 'I', 'like', 'book', 'and', 'I', 'like', 'apple', 'I', 'do', 'not', 'like', 'it', 'I', 'am', 'kitty', 'I', 'like', 'bob', 'I', 'do', 'not', 'care', 'who', 'like', 'bob', 'but', 'I', 'like', 'kitty', 'It', 'is', 'coffee', 'time', 'bring', 'your', 'cup']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(itertools.chain(*docs_words))\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqxnmgjXkJc4",
        "outputId": "236fa81d-3355-478c-c077-98ec24d20d7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I',\n",
              " 'It',\n",
              " 'a',\n",
              " 'am',\n",
              " 'and',\n",
              " 'apple',\n",
              " 'are',\n",
              " 'be',\n",
              " 'bob',\n",
              " 'book',\n",
              " 'bring',\n",
              " 'but',\n",
              " 'care',\n",
              " 'cat',\n",
              " 'coffee',\n",
              " 'cup',\n",
              " 'day',\n",
              " 'do',\n",
              " 'dog',\n",
              " 'good',\n",
              " 'happy',\n",
              " 'hard',\n",
              " 'have',\n",
              " 'here',\n",
              " 'is',\n",
              " 'it',\n",
              " 'kitty',\n",
              " 'like',\n",
              " 'morning',\n",
              " 'not',\n",
              " 'on',\n",
              " 'party',\n",
              " 'stay',\n",
              " 'study',\n",
              " 'sunny',\n",
              " 'that',\n",
              " 'the',\n",
              " 'there',\n",
              " 'this',\n",
              " 'time',\n",
              " 'to',\n",
              " 'today',\n",
              " 'tomorrow',\n",
              " 'tree',\n",
              " 'who',\n",
              " 'will',\n",
              " 'your'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2i = {v: i for i, v in enumerate(vocab)}\n",
        "v2i"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h711yQxMkkHu",
        "outputId": "be74e6da-c33c-43e0-f73a-0afc4a32172b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'I': 35,\n",
              " 'It': 44,\n",
              " 'a': 16,\n",
              " 'am': 11,\n",
              " 'and': 1,\n",
              " 'apple': 20,\n",
              " 'are': 8,\n",
              " 'be': 15,\n",
              " 'bob': 40,\n",
              " 'book': 5,\n",
              " 'bring': 21,\n",
              " 'but': 41,\n",
              " 'care': 30,\n",
              " 'cat': 26,\n",
              " 'coffee': 14,\n",
              " 'cup': 24,\n",
              " 'day': 31,\n",
              " 'do': 27,\n",
              " 'dog': 3,\n",
              " 'good': 33,\n",
              " 'happy': 12,\n",
              " 'hard': 19,\n",
              " 'have': 46,\n",
              " 'here': 42,\n",
              " 'is': 0,\n",
              " 'it': 17,\n",
              " 'kitty': 10,\n",
              " 'like': 18,\n",
              " 'morning': 13,\n",
              " 'not': 38,\n",
              " 'on': 28,\n",
              " 'party': 45,\n",
              " 'stay': 34,\n",
              " 'study': 9,\n",
              " 'sunny': 43,\n",
              " 'that': 23,\n",
              " 'the': 22,\n",
              " 'there': 6,\n",
              " 'this': 25,\n",
              " 'time': 2,\n",
              " 'to': 36,\n",
              " 'today': 32,\n",
              " 'tomorrow': 39,\n",
              " 'tree': 4,\n",
              " 'who': 37,\n",
              " 'will': 7,\n",
              " 'your': 29}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i2v = {i: v for v, i in v2i.items()}\n",
        "i2v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgSq9KDqkosJ",
        "outputId": "cdbd8e48-7bbb-4f54-ec6e-579fa0242dcf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'is',\n",
              " 1: 'and',\n",
              " 2: 'time',\n",
              " 3: 'dog',\n",
              " 4: 'tree',\n",
              " 5: 'book',\n",
              " 6: 'there',\n",
              " 7: 'will',\n",
              " 8: 'are',\n",
              " 9: 'study',\n",
              " 10: 'kitty',\n",
              " 11: 'am',\n",
              " 12: 'happy',\n",
              " 13: 'morning',\n",
              " 14: 'coffee',\n",
              " 15: 'be',\n",
              " 16: 'a',\n",
              " 17: 'it',\n",
              " 18: 'like',\n",
              " 19: 'hard',\n",
              " 20: 'apple',\n",
              " 21: 'bring',\n",
              " 22: 'the',\n",
              " 23: 'that',\n",
              " 24: 'cup',\n",
              " 25: 'this',\n",
              " 26: 'cat',\n",
              " 27: 'do',\n",
              " 28: 'on',\n",
              " 29: 'your',\n",
              " 30: 'care',\n",
              " 31: 'day',\n",
              " 32: 'today',\n",
              " 33: 'good',\n",
              " 34: 'stay',\n",
              " 35: 'I',\n",
              " 36: 'to',\n",
              " 37: 'who',\n",
              " 38: 'not',\n",
              " 39: 'tomorrow',\n",
              " 40: 'bob',\n",
              " 41: 'but',\n",
              " 42: 'here',\n",
              " 43: 'sunny',\n",
              " 44: 'It',\n",
              " 45: 'party',\n",
              " 46: 'have'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper for Log**"
      ],
      "metadata": {
        "id": "6I0m-iL7nCIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_log(x):\n",
        "    mask = x != 0\n",
        "    x[mask] = np.log(x[mask])\n",
        "    return "
      ],
      "metadata": {
        "id": "LERIMZ2OnD41"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF and IDF**"
      ],
      "metadata": {
        "id": "WaaXvBZqnF-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_methods = {\n",
        "        \"log\": lambda x: np.log(1+x),\n",
        "        \"augmented\": lambda x: 0.5 + 0.5 * x / np.max(x, axis=1, keepdims=True),\n",
        "        \"boolean\": lambda x: np.minimum(x, 1),\n",
        "        \"log_avg\": lambda x: (1 + safe_log(x)) / (1 + safe_log(np.mean(x, axis=1, keepdims=True))),\n",
        "    }\n",
        "idf_methods = {\n",
        "        \"log\": lambda x: 1 + np.log(len(docs) / (x+1)),\n",
        "        \"prob\": lambda x: np.maximum(0, np.log((len(docs) - x) / (x+1))),\n",
        "        \"len_norm\": lambda x: x / (np.sum(np.square(x))+1),\n",
        "    }"
      ],
      "metadata": {
        "id": "7o0RWp4anHel"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tf(method=\"log\"):\n",
        "    # term frequency: how frequent a word appears in a doc\n",
        "    _tf = np.zeros((len(vocab), len(docs)), dtype=np.float64)    # [n_vocab, n_doc]\n",
        "    for i, d in enumerate(docs_words):\n",
        "        counter = Counter(d)\n",
        "        for v in counter.keys():\n",
        "            _tf[v2i[v], i] = counter[v] / counter.most_common(1)[0][1]\n",
        "\n",
        "    weighted_tf = tf_methods.get(method, None)\n",
        "    if weighted_tf is None:\n",
        "        raise ValueError\n",
        "    return weighted_tf(_tf)"
      ],
      "metadata": {
        "id": "F87k8rd-nOSM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_idf(method=\"log\"):\n",
        "    # inverse document frequency: low idf for a word appears in more docs, mean less important\n",
        "    df = np.zeros((len(i2v), 1))\n",
        "    for i in range(len(i2v)):\n",
        "        d_count = 0\n",
        "        for d in docs_words:\n",
        "            d_count += 1 if i2v[i] in d else 0\n",
        "        df[i, 0] = d_count\n",
        "\n",
        "    idf_fn = idf_methods.get(method, None)\n",
        "    if idf_fn is None:\n",
        "        raise ValueError\n",
        "    return idf_fn(df)"
      ],
      "metadata": {
        "id": "5OxTYhjXnQTk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(q, _tf_idf):\n",
        "    unit_q = q / np.sqrt(np.sum(np.square(q), axis=0, keepdims=True))\n",
        "    unit_ds = _tf_idf / np.sqrt(np.sum(np.square(_tf_idf), axis=0, keepdims=True))\n",
        "    similarity = unit_ds.T.dot(unit_q).ravel()\n",
        "    return "
      ],
      "metadata": {
        "id": "RvFj9kCtnSyO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def docs_score(q, len_norm=False):\n",
        "    q_words = q.replace(\",\", \"\").split(\" \")\n",
        "\n",
        "    # add unknown words\n",
        "    unknown_v = 0\n",
        "    for v in set(q_words):\n",
        "        if v not in v2i:\n",
        "            v2i[v] = len(v2i)\n",
        "            i2v[len(v2i)-1] = v\n",
        "            unknown_v += 1\n",
        "    if unknown_v > 0:\n",
        "        _idf = np.concatenate((idf, np.zeros((unknown_v, 1), dtype=np.float)), axis=0)\n",
        "        _tf_idf = np.concatenate((tf_idf, np.zeros((unknown_v, tf_idf.shape[1]), dtype=np.float)), axis=0)\n",
        "    else:\n",
        "        _idf, _tf_idf = idf, tf_idf\n",
        "    counter = Counter(q_words)\n",
        "    q_tf = np.zeros((len(_idf), 1), dtype=np.float)     # [n_vocab, 1]\n",
        "    for v in counter.keys():\n",
        "        q_tf[v2i[v]-1, 0] = counter[v]\n",
        "\n",
        "    q_vec = q_tf * _idf            # [n_vocab, 1]\n",
        "\n",
        "    q_scores = cosine_similarity(q_vec, _tf_idf)\n",
        "    if len_norm:\n",
        "        len_docs = [len(d) for d in docs_words]\n",
        "        q_scores = q_scores / np.array(len_docs)\n",
        "    return q_scores"
      ],
      "metadata": {
        "id": "4syhsD1WnU5t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keywords(n=2):\n",
        "    for c in range(3):\n",
        "        col = tf_idf[:, c]\n",
        "        idx = np.argsort(col)[-n:]\n",
        "        print(\"doc{}, top{} keywords {}\".format(c, n, [i2v[i] for i in idx]))"
      ],
      "metadata": {
        "id": "kS3KabgbndJl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Value for Fake Data**"
      ],
      "metadata": {
        "id": "95_Jo9HXnilF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf = get_tf()           # [n_vocab, n_doc]\n",
        "idf = get_idf()         # [n_vocab, 1]\n",
        "tf_idf = tf * idf       # [n_vocab, n_doc]\n",
        "print(\"tf shape(vecb in each docs): \", tf.shape)\n",
        "print(\"\\ntf samples:\\n\", tf[:2])\n",
        "print(\"\\nidf shape(vecb in all docs): \", idf.shape)\n",
        "print(\"\\nidf samples:\\n\", idf[:2])\n",
        "print(\"\\ntf_idf shape: \", tf_idf.shape)\n",
        "print(\"\\ntf_idf sample:\\n\", tf_idf[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_fsA7QbnfYV",
        "outputId": "303db8dd-061e-4a49-b4b5-3e4f3d2b1206"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf shape(vecb in each docs):  (47, 15)\n",
            "\n",
            "tf samples:\n",
            " [[0.69314718 0.         0.         0.69314718 0.         0.69314718\n",
            "  0.         0.         0.69314718 0.         0.         0.\n",
            "  0.         0.         0.69314718]\n",
            " [0.         0.         0.         0.         0.         0.40546511\n",
            "  0.69314718 0.         0.         0.         0.28768207 0.\n",
            "  0.         0.         0.        ]]\n",
            "\n",
            "idf shape(vecb in all docs):  (47, 1)\n",
            "\n",
            "idf samples:\n",
            " [[1.91629073]\n",
            " [2.32175584]]\n",
            "\n",
            "tf_idf shape:  (47, 15)\n",
            "\n",
            "tf_idf sample:\n",
            " [[1.32827152 0.         0.         1.32827152 0.         1.32827152\n",
            "  0.         0.         1.32827152 0.         0.         0.\n",
            "  0.         0.         1.32827152]\n",
            " [0.         0.         0.         0.         0.         0.94139098\n",
            "  1.60931851 0.         0.         0.         0.66792753 0.\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_keywords()\n",
        "q = \"I get a coffee cup\"\n",
        "scores = docs_score(q)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmwGMxzOnoI1",
        "outputId": "4bbe7cca-a72b-4642-9ad2-3da31f8d4797"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doc0, top2 keywords ['to', 'stay']\n",
            "doc1, top2 keywords ['here', 'happy']\n",
            "doc2, top2 keywords ['am', 'bob']\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    }
  ]
}